
# RAG-система для медицинской клиники с интеграцией Langfuse

## Описание проекта

Этот проект представляет собой Retrieval-Augmented Generation (RAG) систему, разработанную для медицинской клиники. Система позволяет пользователям задавать вопросы о медицинских услугах и получать точные ответы на основе базы знаний клиники. Проект использует современные технологии ИИ для обработки естественного языка и обеспечивает высокую точность ответов благодаря комбинации поиска по векторной базе данных и генеративной модели.

Основные возможности:
- Ответы на вопросы о записи к врачу, документах, анализах, вакцинации и других услугах клиники
- Интеграция с Langfuse для отслеживания и анализа запросов
- Веб-интерфейс на базе Streamlit
- Контейнеризация с помощью Docker
- Поддержка русского языка

## Анализ проекта

### Архитектура системы

Проект построен на следующих компонентах:

1. **База знаний**: Хардкодированные вопросы и ответы о медицинских услугах клиники в формате JSON
2. **Векторизация**: Использование модели `intfloat/multilingual-e5-large` для создания эмбеддингов
3. **Векторное хранилище**: FAISS для эффективного поиска релевантных документов
4. **Генеративная модель**: `Den4ikAI/rubert_large_squad_2` для генерации ответов на русском языке
5. **Фреймворк**: Langchain для оркестрации RAG-пайплайна
6. **Мониторинг**: Langfuse для трейсинга, логирования и оценки качества ответов
7. **UI**: Streamlit для создания интерактивного веб-интерфейса

### Как работает система

1. **Подготовка данных**: Документы загружаются из DataFrame, разбиваются на чанки и векторизуются
2. **Обработка запроса**: Пользовательский вопрос векторизуется и ищется в FAISS
3. **Генерация ответа**: На основе найденного контекста генерируется ответ с помощью LLM
4. **Оценка**: Langfuse оценивает релевантность и полноту ответа
5. **Логирование**: Все взаимодействия записываются для анализа и улучшения

### Преимущества

- **Точность**: Комбинация поиска и генерации обеспечивает высококачественные ответы
- **Масштабируемость**: Легко добавить новые документы в базу знаний
- **Наблюдаемость**: Полный трекинг запросов и ответов через Langfuse
- **Локализация**: Поддержка русского языка для медицинской тематики
- **Простота развертывания**: Docker-контейнер для быстрого запуска

## Установка и настройка

### Требования

- Python 3.9+
- Docker (опционально)
- Аккаунты в Hugging Face и Langfuse

### Локальная установка

1. Клонируйте репозиторий:
   ```bash
   git clone <repository-url>
   cd Rag_langfuse_project
   ```

2. Создайте виртуальное окружение:
   ```bash
   python3 -m venv venv
   ```

3. Активируйте окружение:
   ```bash
   source venv/bin/activate
   ```

4. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

5. Создайте файл `.env` в корне проекта и добавьте переменные окружения:
   ```
   HF_TOKEN=ваш_huggingface_token
   LANGFUSE_PUBLIC_KEY=ваш_langfuse_public_key
   LANGFUSE_SECRET_KEY=ваш_langfuse_secret_key
   ```

6. Запустите приложение:
   ```bash
   streamlit run ui.py
   ```
Шаги для Windows ## Установка

1. Клонируйте репозиторий.
2. Установите зависимости:

python3 -m venv venv

source venv/bin/activate

```bash
pip install -r requirements.txt

Запуск RAG-системы:
python main.py


Запуск Streamlit приложения:
 streamlit run app.py
 
Приложение будет доступно по адресу `http://localhost:8501`

### Остановка приложения

Чтобы остановить приложение, используйте команду:
```bash
pkill -f streamlit
```

### Запуск в Docker

1. Соберите образ:
   ```bash
   docker build -t rag-clinic .
   ```

2. Запустите контейнер:
   ```bash
   docker run -p 8501:8501 --env-file .env rag-clinic
   ```

### Запуск с Docker Compose

Docker Compose позволяет запускать приложение с помощью простого файла конфигурации `docker-compose.yml`, который автоматически управляет сборкой образа и запуском контейнера.

1. Убедитесь, что у вас установлен Docker Compose:
   ```bash
   docker-compose --version
   ```

2. Создайте файл `.env` в корне проекта с необходимыми переменными окружения:
   ```
   HF_TOKEN=ваш_huggingface_token
   LANGFUSE_PUBLIC_KEY=ваш_langfuse_public_key
   LANGFUSE_SECRET_KEY=ваш_langfuse_secret_key
   ```

3. Запустите приложение с помощью Docker Compose:
   ```bash
   docker-compose up --build
   ```

   Флаг `--build` заставляет Docker Compose пересобрать образ, если были изменения в коде.

4. Приложение будет доступно по адресу `http://localhost:8501`

5. Для запуска в фоновом режиме используйте:
   ```bash
   docker-compose up -d --build
   ```

6. Чтобы остановить приложение:
   ```bash
   docker-compose down
   ```

#### Преимущества Docker Compose

- **Автоматическая сборка**: Не нужно вручную собирать образ
- **Управление конфигурацией**: Все настройки в одном файле
- **Масштабируемость**: Легко добавить новые сервисы
- **Восстановление**: Контейнер автоматически перезапускается при сбое

## Использование

1. Откройте веб-интерфейс в браузере
2. Введите вопрос о медицинских услугах клиники
3. Получите ответ с ссылкой на дополнительную информацию
4. Все взаимодействия автоматически логируются в Langfuse

### Примеры вопросов

- "Как записаться на прием к врачу?"
- "Какие документы нужны для первого визита?"
- "Как подготовиться к УЗИ?"
- "Как получить результаты анализов?"

## Структура проекта

```
Rag_langfuse_project/
├── main.py              # Основной файл приложения
├── requirements.txt     # Зависимости Python
├── Dockerfile          # Конфигурация Docker
├── docker-compose.yml  # Конфигурация Docker Compose
├── .gitignore          # Игнорируемые файлы Git
├── README.md           # Документация
└── .env                # Переменные окружения (не в репозитории)
```

## Технологии

- **Python 3.9**
- **Streamlit** - веб-фреймворк
- **Langchain** - фреймворк для LLM приложений
- **Hugging Face Transformers** - модели ИИ
- **FAISS** - векторное хранилище
- **Langfuse** - платформа для наблюдения за LLM
- **Docker** - контейнеризация

## Разработка и расширение

### Добавление новых документов

Для расширения базы знаний добавьте новые записи в список `documents` в `main.py`:

```python
{
    "id": 16,
    "question": "Ваш новый вопрос",
    "answer": "Подробный ответ",
    "url": "clinic/new-topic"
}
```

### Настройка моделей

Можно заменить модели в коде:
- Эмбеддинги: изменить `model_name` в `HuggingFaceEmbeddings`
- LLM: изменить `repo_id` в `HuggingFaceHub`

### Мониторинг

Langfuse предоставляет дашборд для анализа:
- Количество запросов
- Качество ответов
- Время отклика
- Распределение тем

## Лицензия

[Укажите лицензию проекта]

## Контакты

Николай 
тел. +79101204721
